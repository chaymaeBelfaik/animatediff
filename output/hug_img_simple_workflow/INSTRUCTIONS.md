# Hugging Video Generation Instructions

## Input Image
- **Original**: input/hug-img.jpg
- **Resized**: input_resized.png (512x512)
- **2-Person Pose Reference**: input_poses.png (shows 2 people in initial standing position)

## Skeleton Frames
- **Location**: skeleton_frames/
- **Files**: control_000.png to control_015.png (16 frames)
- **Type**: Clean stick figure skeletons showing walking to hugging motion

## ComfyUI Manual Setup

### Required Models
- **ControlNet**: control_v11p_sd15_openpose.pth
- **Stable Diffusion**: stable-diffusion-v1-5.ckpt or any SD 1.5 model

### Node Setup
1. **LoadImage** → Load each skeleton frame (control_000.png to control_015.png)
2. **ControlNetLoader** → Load OpenPose ControlNet model
3. **ControlNetApply** → Apply skeleton control
   - Strength: 1.0-1.2 (adjust as needed)
   - Start: 0.0, End: 1.0
4. **CLIPTextEncode** (Positive) → "two people hugging, warm embrace, emotional moment, high quality, detailed, realistic, beautiful lighting"
5. **CLIPTextEncode** (Negative) → "text, watermark, blurry, low quality, distorted"
6. **CheckpointLoaderSimple** → Load your SD model
7. **KSampler** → Generate images
   - Steps: 25-30
   - CFG: 7.5-8.0
   - Sampler: euler_ancestral
   - Scheduler: normal
8. **SaveImage** → Save generated frames

### Processing Steps
1. Process each skeleton frame individually
2. Use the same prompt and settings for all frames
3. Keep seed consistent for style coherence
4. Save frames as: generated_000.png to generated_015.png

### Video Creation
After generating all frames, create video with FFmpeg:
```bash
ffmpeg -framerate 8 -i generated_%03d.png -c:v libx264 -pix_fmt yuv420p hugging_video.mp4
```

## Settings Recommendations
- **ControlNet Strength**: 1.0 (increase for stricter pose following)
- **Steps**: 25-30 (higher for better quality)
- **CFG Scale**: 7.5-8.0 (higher for stronger prompt adherence)
- **Resolution**: 512x512 (matches skeleton frames)

## Tips
- Use the input image as style reference
- Adjust ControlNet strength if poses are too rigid or loose
- Keep lighting and clothing consistent in prompt
- Consider using img2img with input image as base

## Troubleshooting
- **Poses don't match**: Increase ControlNet strength
- **Poor quality**: Increase steps and CFG scale
- **Inconsistent style**: Use same seed across all frames
- **Wrong poses**: Check skeleton frame order

---
Generated by Simple Input to Hugging Video Generator
